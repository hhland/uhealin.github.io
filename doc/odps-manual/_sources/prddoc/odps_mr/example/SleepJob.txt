SleepJob代码示例
----------------------------------------------------------------------------------------
代码示例，仅供参考：

.. code-block:: java
 :linenos:

  package com.aliyun.odps.mapred.open.example;
  
  import java.io.IOException;
  import java.util.Iterator;
  import java.util.LinkedHashMap;
  import java.util.Map;
  
  import org.apache.commons.logging.Log;
  import org.apache.commons.logging.LogFactory;
  
  import com.aliyun.odps.OdpsException;
  import com.aliyun.odps.data.Record;
  import com.aliyun.odps.data.TableInfo;
  import com.aliyun.odps.mapred.JobClient;
  import com.aliyun.odps.mapred.MapperBase;
  import com.aliyun.odps.mapred.ReducerBase;
  import com.aliyun.odps.mapred.TaskContext;
  import com.aliyun.odps.mapred.conf.JobConf;
  import com.aliyun.odps.mapred.utils.InputUtils;
  import com.aliyun.odps.mapred.utils.OutputUtils;
  import com.aliyun.odps.mapred.utils.SchemaUtils;
  
  /**
   * Dummy class for testing MR framefork. Sleeps for a defined period of time in
   * mapper and reducer. Generates fake input for map / reduce jobs. Note that
   * generated number of input pairs is in the order of
   * <code>numMappers * mapSleepTime / 100</code>, so the job uses some disk
   * space.
   * To run: jar -resources odps-mapred-example-0.12.0.jar com.aliyun.odps.mapred.open.example.SleepJob 
   * -m 1 -r 1 -mt 1 -rt 1;
   * 
   **/
  public class SleepJob {
  
    private static Log LOG = LogFactory.getLog(SleepJob.class);
  
    public static class SleepMapper extends MapperBase {
  
      private LinkedHashMap<Integer, Integer> inputs = new LinkedHashMap<Integer, Integer>();
      private long mapSleepDuration = 100;
      private int mapSleepCount = 1;
      private int count = 0;
      private Record key;
  
      @Override
      public void setup(TaskContext context) throws IOException {
        LOG.info("map setup called");
        JobConf conf = (JobConf) context.getJobConf();
  
        mapSleepCount = conf.getInt("sleep.job.map.sleep.count", 1);
        if (mapSleepCount < 0)
          throw new IOException("Invalid map count: " + mapSleepCount);
  
        mapSleepDuration = conf.getLong("sleep.job.map.sleep.time", 100)
            / mapSleepCount;
  
        LOG.info("mapSleepCount = " + mapSleepCount + ", mapSleepDuration = "
            + mapSleepDuration);
  
        final int redcount = conf.getInt("sleep.job.reduce.sleep.count", 1);
        if (redcount < 0)
          throw new IOException("Invalid reduce count: " + redcount);
  
        final int emitPerMapTask = (redcount * conf.getNumReduceTasks());
  
        int records = 0;
        int emitCount = 0;
  
        while (records++ < mapSleepCount) {
          int key = emitCount;
          int emit = emitPerMapTask / mapSleepCount;
          if ((emitPerMapTask) % mapSleepCount > records) {
            ++emit;
          }
          emitCount += emit;
          int value = emit;
          inputs.put(key, value);
        }
  
        key = context.createMapOutputKeyRecord();
      }
  
      @Override
      public void cleanup(TaskContext context) throws IOException {
        // it is expected that every map processes mapSleepCount number of
        // records.
        LOG.info("map run called");
   
        for (Map.Entry<Integer, Integer> entry : inputs.entrySet()) {
          LOG.info("Sleeping... (" + (mapSleepDuration * (mapSleepCount - count))
              + ") ms left");
          try {
            Thread.sleep(mapSleepDuration);
          } catch (InterruptedException e) {
            throw new IOException(e);
          }
  
          ++count;
          // output reduceSleepCount * numReduce number of random values, so that
          // each reducer will get reduceSleepCount number of keys.
          int k = entry.getKey();
          int v = entry.getValue();
          for (int i = 0; i < v; ++i) {
            key.set(new Object[] { (Long) ((long) (k + i)) });
            context.write(key, key);
          }
        }
      }
    }
  
    public static class SleepReducer extends ReducerBase {
  
      private long reduceSleepDuration = 100;
  
      private int reduceSleepCount = 1;
      private int count = 0;
  
      @Override
      public void setup(TaskContext context) throws IOException {
        LOG.info("reduce setup called");
        JobConf conf = (JobConf) context.getJobConf();
        reduceSleepCount = conf.getInt("sleep.job.reduce.sleep.count",
            reduceSleepCount);
        reduceSleepDuration = conf.getLong("sleep.job.reduce.sleep.time", 100)
            / reduceSleepCount;
        LOG.info("reduceSleepCount = " + reduceSleepCount
            + ", reduceSleepDuration = " + reduceSleepDuration);
      }
  
      @Override
      public void reduce(Record key, Iterator<Record> values, TaskContext context)
          throws IOException {
        LOG.info("reduce called");
  
        LOG.info("Sleeping... ("
            + (reduceSleepDuration * (reduceSleepCount - count)) + ") ms left");
        try {
          Thread.sleep(reduceSleepDuration);
        } catch (InterruptedException e) {
          throw new IOException(e);
        }
  
        count++;
      }
    }
  
    public static int run(int numMapper, int numReducer, long mapSleepTime,
        int mapSleepCount, long reduceSleepTime, int reduceSleepCount)
        throws OdpsException {
      JobConf job = setupJobConf(numMapper, numReducer, mapSleepTime,
          mapSleepCount, reduceSleepTime, reduceSleepCount);
      JobClient.runJob(job);
      return 0;
    }
  
    public static JobConf setupJobConf(int numMapper, int numReducer,
        long mapSleepTime, int mapSleepCount, long reduceSleepTime,
        int reduceSleepCount) {
      JobConf job = new JobConf();
      
      InputUtils.addTable(TableInfo.builder().tableName("mr_empty").build(), job);
      OutputUtils.addTable(TableInfo.builder().tableName("mr_sleep_out").build(), job);
  
      job.setNumReduceTasks(numReducer);
  
      job.setMapperClass(SleepMapper.class);
      job.setReducerClass(SleepReducer.class);
  
      job.setMapOutputKeySchema(SchemaUtils.fromString("int1:bigint"));
      job.setMapOutputValueSchema(SchemaUtils.fromString("int2:bigint"));
      job.setPartitionColumns(new String[] { "int1" });
  
      job.setLong("sleep.job.map.sleep.time", mapSleepTime);
      job.setLong("sleep.job.reduce.sleep.time", reduceSleepTime);
      job.setInt("sleep.job.map.sleep.count", mapSleepCount);
      job.setInt("sleep.job.reduce.sleep.count", reduceSleepCount);
  
      return job;
    }
  
    private static void printUsage() {
      System.err.println("SleepJob [-m numMapper] [-r numReducer]"
          + " [-mt mapSleepTime (msec)] [-rt reduceSleepTime (msec)]"
          + " [-recordt recordSleepTime (msec)]");
    }
  
    public static void main(String[] args) throws Exception {
  
      if (args.length < 1) {
        printUsage();
        return;
      }
  
      int numMapper = 1, numReducer = 1;
      long mapSleepTime = 100, reduceSleepTime = 100, recSleepTime = 100;
      int mapSleepCount = 1, reduceSleepCount = 1;
  
      for (int i = 0; i < args.length; i++) {
        if (args[i].equals("-m")) {
          numMapper = Integer.parseInt(args[++i]);
        } else if (args[i].equals("-r")) {
          numReducer = Integer.parseInt(args[++i]);
        } else if (args[i].equals("-mt")) {
          mapSleepTime = Long.parseLong(args[++i]);
        } else if (args[i].equals("-rt")) {
          reduceSleepTime = Long.parseLong(args[++i]);
        } else if (args[i].equals("-recordt")) {
          recSleepTime = Long.parseLong(args[++i]);
        }
      }
  
      // sleep for *SleepTime duration in Task by recSleepTime per record
      mapSleepCount = (int) Math.ceil(mapSleepTime / ((double) recSleepTime));
      reduceSleepCount = (int) Math.ceil(reduceSleepTime
          / ((double) recSleepTime));
  
      run(numMapper, numReducer, mapSleepTime, mapSleepCount, reduceSleepTime,
          reduceSleepCount);
    }
  
  }
