二次排序源代码
----------------------------------------------------------------------------------------
代码示例，仅供参考：

.. code-block:: java
 :linenos:

  package com.aliyun.odps.mapred.open.example;
  
  import java.io.IOException;
  import java.util.Iterator;
  
  import com.aliyun.odps.data.Record;
  import com.aliyun.odps.mapred.JobClient;
  import com.aliyun.odps.mapred.MapperBase;
  import com.aliyun.odps.mapred.ReducerBase;
  import com.aliyun.odps.mapred.TaskContext;
  import com.aliyun.odps.mapred.conf.JobConf;
  import com.aliyun.odps.mapred.example.utils.TableInputFormat;
  import com.aliyun.odps.mapred.example.utils.TableOutputFormat;
  import com.aliyun.odps.mapred.utils.SchemaUtils;
  
  /**
   * This is an example ODPS Map/Reduce application. It reads the input table that
   * must contain two integers per record. The output is sorted by the first and
   * second number and grouped on the first number.
   * 
   * To run: jar -resources odps-mapred-example-0.12.0.jar 
   * com.aliyun.odps.mapred.open.example.SecondarySort mr_sort_in mr_secondarysort_out;
   * 
   **/
  public class SecondarySort {
  
    /**
     * Read two integers from each line and generate a key, value pair as ((left,
     * right), right).
     **/
    public static class MapClass extends MapperBase {
      private Record key;
      private Record value;
  
      @Override
      public void setup(TaskContext context) throws IOException {
        key = context.createMapOutputKeyRecord();
        value = context.createMapOutputValueRecord();
      }
  
      @Override
      public void map(long recordNum, Record record, TaskContext context)
          throws IOException {
        long left = 0;
        long right = 0;
  
        if (record.getColumnCount() > 0) {
          left = (Long) record.get(0);
          if (record.getColumnCount() > 1) {
            right = (Long) record.get(1);
          }
  
          key.set(new Object[] { (Long) left, (Long) right });
          value.set(new Object[] { (Long) right });
  
          context.write(key, value);
        }
      }
    }
  
    /**
     * A reducer class that just emits the sum of the input values.
     **/
    public static class ReduceClass extends ReducerBase {
  
      private Record result = null;
  
      @Override
      public void setup(TaskContext context) throws IOException {
        result = context.createOutputRecord();
      }
  
      @Override
      public void reduce(Record key, Iterator<Record> values, TaskContext context)
          throws IOException {
        result.set(0, key.get(0));
        while (values.hasNext()) {
          Record value = values.next();
          result.set(1, value.get(0));
          context.write(result);
        }
      }
  
    }
  
    public static void main(String[] args) throws Exception {
      if (args.length != 2) {
        System.err.println("Usage: secondarysrot <in> <out>");
        System.exit(2);
      }
  
      JobConf job = new JobConf();
      job.setMapperClass(MapClass.class);
      job.setReducerClass(ReduceClass.class);
 
      //将多列设置为Key 
      // compare first and second parts of the pair
      job.setOutputKeySortColumns(new String[] { "i1", "i2" });
  
      // partition based on the first part of the pair
      job.setPartitionColumns(new String[] { "i1" });
  
      // grouping comparator based on the first part of the pair
      job.setOutputGroupingColumns(new String[] { "i1" });
  
      // the map output is LongPair, Long
      job.setMapOutputKeySchema(SchemaUtils.fromString("i1:bigint,i2:bigint"));
      job.setMapOutputValueSchema(SchemaUtils.fromString("i2x:bigint"));
  
      TableInputFormat.addInput(args[0], job);
      TableOutputFormat.addOutput(args[1], job);
  
      JobClient.runJob(job);
      System.exit(0);
    }
  
  }
